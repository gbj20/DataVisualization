{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Load and prepare MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Define the model architecture\n",
        "model = models.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf85ogvUGcAc",
        "outputId": "cac34861-9a84-4b8b-dcea-94ca83e2efaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 13s 6ms/step - loss: 0.2971 - accuracy: 0.9137\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1474 - accuracy: 0.9558\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1120 - accuracy: 0.9661\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0904 - accuracy: 0.9718\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0781 - accuracy: 0.9756\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0793 - accuracy: 0.9760\n",
            "Test accuracy: 0.9760000109672546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load pre-trained model\n",
        "model = tf.keras.applications.ResNet50(include_top=True, weights='imagenet')\n",
        "\n",
        "# Load MNIST data\n",
        "mnist_data = tf.keras.datasets.mnist\n",
        "(_, _), (x_test, y_test) = mnist_data.load_data()\n",
        "x_test = tf.image.grayscale_to_rgb(tf.expand_dims(x_test, axis=-1))\n",
        "\n",
        "# Choose a random image from MNIST dataset\n",
        "image = x_test[1]\n",
        "\n",
        "# Resize the image to match the input shape of the ResNet50 model\n",
        "image_resized = tf.image.resize(image, (224, 224))\n",
        "\n",
        "# Make prediction\n",
        "output = model.predict(image_resized[np.newaxis, ...])\n",
        "\n",
        "# Get predicted label\n",
        "predicted = tf.argmax(output, axis=-1)\n",
        "\n",
        "# Display image and predicted label\n",
        "plt.imshow(image.numpy().squeeze(), cmap='gray')\n",
        "plt.title(f'Predicted Label: {predicted.item()}, Actual Label: {y_test[0]}')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "id": "g3lepJqgIcbJ",
        "outputId": "9721b18f-fa22-493d-d93a-a81d20bc3ab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'item'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-0250adda44c7>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Display image and predicted label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Predicted Label: {predicted.item()}, Actual Label: {y_test[0]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_enable_numpy_behavior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m       \"\"\")\n\u001b[0;32m--> 261\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'item'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handwritten Digit Recognition on MNIST dataset**\n",
        "1. First of all, import all the libraries required. We will import the fetch_openml from the sklearn.datasets library.\n",
        "\n",
        "2. Create a variable mnist, and store in it the mnsit_784 dataset from the featch_openml And you can further print and see the contents of this mnist dataset. You can see its keys, its data, its corresponding labels, and more."
      ],
      "metadata": {
        "id": "cntlhf8D58Is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fetching dataset\n",
        "from sklearn.datasets import fetch_openml\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "mnist = fetch_openml('mnist_784')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIgOQi0f56lf",
        "outputId": "1603ef5f-8c58-4a7e-edc8-a24954ed6845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Slicing the dataset, and plotting the images**\n",
        "3. Create array variables x and y. Store in them the data and the targets respectively of the mnist As we discussed above, we have 784 (28x28) pixels of features, and these are now stored in x. Variable y has the corresponding digit that the picture resembled by x contains.\n",
        "\n",
        "4. You can try to see that picture x using matplotlib Since the pixels here are stacked together in a 1D array x for memory issues, you’ll have to reshape it back to 26x26. Create a variable some_digit and fill it with any random digit array from the dataset. Reshape it and store it in another variable some_digit_image.\n",
        "\n",
        "5. You can now simply use the command below to get that image plotted. We have used the imshow attribute of pyplot and have fed the some_digit_image 2D array of pixel data into it."
      ],
      "metadata": {
        "id": "WjGU8KJN6tUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = mnist['data'], mnist['target']\n",
        "\n",
        "some_digit = x.to_numpy()[36001]\n",
        "some_digit_image = some_digit.reshape(28, 28)  # let's reshape to plot it\n",
        "\n",
        "plt.imshow(some_digit_image, cmap=matplotlib.cm.binary,\n",
        "           interpolation='nearest')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tTW1QzDV7Dlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. And since the data, we stored corresponded to the 36000th element, the image we were shown was:"
      ],
      "metadata": {
        "id": "-P2MY2fG7Jdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = mnist['data'], mnist['target']\n",
        "\n",
        "some_digit = x.to_numpy()[36001]\n",
        "some_digit_image = some_digit.reshape(28, 28)  # let's reshape to plot it\n",
        "\n",
        "plt.imshow(some_digit_image, cmap=matplotlib.cm.binary,\n",
        "           interpolation='nearest')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "FAoFCLjC7vWJ",
        "outputId": "f690a635-c84a-4a40-8e8d-0678a98c98d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}